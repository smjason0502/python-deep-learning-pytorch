{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smjason0502/python-deep-learning-pytorch/blob/main/Part_04_%EB%B9%88%EC%B9%B8_%EC%B6%94%EA%B0%80%EB%AC%B8%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdpAYC3VnMR8"
      },
      "source": [
        "# 대용량의 데이터를 이용해 학습이 완료된 모델을 적은 수의 데이터에 맞게 Fine-tuning하는 Transfer Learning를 GoogLeNet으로 실습해보기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0RmTqBLVZxP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aac3d198-fd3e-45eb-8bd0-7dbcdae90e16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using PyTorch version: 2.4.1+cu121  Device: cuda\n",
            "--2024-09-28 11:10:18--  https://download.pytorch.org/tutorial/hymenoptera_data.zip\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 3.165.102.31, 3.165.102.113, 3.165.102.36, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|3.165.102.31|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 47286322 (45M) [application/zip]\n",
            "Saving to: ‘hymenoptera_data.zip’\n",
            "\n",
            "hymenoptera_data.zi 100%[===================>]  45.10M   238MB/s    in 0.2s    \n",
            "\n",
            "2024-09-28 11:10:19 (238 MB/s) - ‘hymenoptera_data.zip’ saved [47286322/47286322]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/googlenet.py:47: FutureWarning: The default weight initialization of GoogleNet will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GoogLeNet(\n",
            "  (conv1): BasicConv2d(\n",
            "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "  (conv2): BasicConv2d(\n",
            "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv3): BasicConv2d(\n",
            "    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "  (inception3a): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception3b): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "  (inception4a): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception4b): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception4c): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception4d): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception4e): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "  (inception5a): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception5b): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (aux1): InceptionAux(\n",
            "    (conv): BasicConv2d(\n",
            "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "    (fc2): Linear(in_features=1024, out_features=1000, bias=True)\n",
            "    (dropout): Dropout(p=0.7, inplace=False)\n",
            "  )\n",
            "  (aux2): InceptionAux(\n",
            "    (conv): BasicConv2d(\n",
            "      (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "    (fc2): Linear(in_features=1024, out_features=1000, bias=True)\n",
            "    (dropout): Dropout(p=0.7, inplace=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
            ")\n",
            "미리 학습되지 않은 GoogLeNet 학습을 실행하며 Test set의 Loss와 Accuracy 확인하기 \n",
            "\n",
            "Train Epoch: 1 [0/244 (0%)]\tTrain Loss: 0.707559\n",
            "Train Epoch: 1 [160/244 (62%)]\tTrain Loss: 0.575975\n",
            "\n",
            "[EPOCH: 1], \tTest Loss: 0.0227, \tTest Accuracy: 45.75 % \n",
            "\n",
            "Train Epoch: 2 [0/244 (0%)]\tTrain Loss: 0.610737\n",
            "Train Epoch: 2 [160/244 (62%)]\tTrain Loss: 0.629722\n",
            "\n",
            "[EPOCH: 2], \tTest Loss: 0.0229, \tTest Accuracy: 45.75 % \n",
            "\n",
            "Train Epoch: 3 [0/244 (0%)]\tTrain Loss: 0.645413\n",
            "Train Epoch: 3 [160/244 (62%)]\tTrain Loss: 0.580470\n",
            "\n",
            "[EPOCH: 3], \tTest Loss: 0.0235, \tTest Accuracy: 45.75 % \n",
            "\n",
            "Train Epoch: 4 [0/244 (0%)]\tTrain Loss: 0.447319\n",
            "Train Epoch: 4 [160/244 (62%)]\tTrain Loss: 0.660100\n",
            "\n",
            "[EPOCH: 4], \tTest Loss: 0.0281, \tTest Accuracy: 45.75 % \n",
            "\n",
            "Train Epoch: 5 [0/244 (0%)]\tTrain Loss: 0.351702\n",
            "Train Epoch: 5 [160/244 (62%)]\tTrain Loss: 0.471772\n",
            "\n",
            "[EPOCH: 5], \tTest Loss: 0.0353, \tTest Accuracy: 45.75 % \n",
            "\n",
            "Train Epoch: 6 [0/244 (0%)]\tTrain Loss: 0.365957\n",
            "Train Epoch: 6 [160/244 (62%)]\tTrain Loss: 0.491983\n",
            "\n",
            "[EPOCH: 6], \tTest Loss: 0.0303, \tTest Accuracy: 45.75 % \n",
            "\n",
            "Train Epoch: 7 [0/244 (0%)]\tTrain Loss: 0.473005\n",
            "Train Epoch: 7 [160/244 (62%)]\tTrain Loss: 0.382159\n",
            "\n",
            "[EPOCH: 7], \tTest Loss: 0.0585, \tTest Accuracy: 45.75 % \n",
            "\n",
            "Train Epoch: 8 [0/244 (0%)]\tTrain Loss: 0.392553\n",
            "Train Epoch: 8 [160/244 (62%)]\tTrain Loss: 0.524118\n",
            "\n",
            "[EPOCH: 8], \tTest Loss: 0.0293, \tTest Accuracy: 60.78 % \n",
            "\n",
            "Train Epoch: 9 [0/244 (0%)]\tTrain Loss: 0.406658\n",
            "Train Epoch: 9 [160/244 (62%)]\tTrain Loss: 0.412036\n",
            "\n",
            "[EPOCH: 9], \tTest Loss: 0.0178, \tTest Accuracy: 75.82 % \n",
            "\n",
            "Train Epoch: 10 [0/244 (0%)]\tTrain Loss: 0.296604\n",
            "Train Epoch: 10 [160/244 (62%)]\tTrain Loss: 0.370800\n",
            "\n",
            "[EPOCH: 10], \tTest Loss: 0.0234, \tTest Accuracy: 71.24 % \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/244 (0%)]\tTrain Loss: 0.694229\n",
            "Train Epoch: 1 [160/244 (62%)]\tTrain Loss: 0.524859\n",
            "\n",
            "[EPOCH: 1], \tTest Loss: 0.0146, \tTest Accuracy: 93.46% \n",
            "\n",
            "Train Epoch: 2 [0/244 (0%)]\tTrain Loss: 0.473990\n",
            "Train Epoch: 2 [160/244 (62%)]\tTrain Loss: 0.356648\n",
            "\n",
            "[EPOCH: 2], \tTest Loss: 0.0102, \tTest Accuracy: 92.81% \n",
            "\n",
            "Train Epoch: 3 [0/244 (0%)]\tTrain Loss: 0.289889\n",
            "Train Epoch: 3 [160/244 (62%)]\tTrain Loss: 0.255627\n",
            "\n",
            "[EPOCH: 3], \tTest Loss: 0.0078, \tTest Accuracy: 94.12% \n",
            "\n",
            "Train Epoch: 4 [0/244 (0%)]\tTrain Loss: 0.242904\n",
            "Train Epoch: 4 [160/244 (62%)]\tTrain Loss: 0.197370\n",
            "\n",
            "[EPOCH: 4], \tTest Loss: 0.0066, \tTest Accuracy: 94.77% \n",
            "\n",
            "Train Epoch: 5 [0/244 (0%)]\tTrain Loss: 0.209389\n",
            "Train Epoch: 5 [160/244 (62%)]\tTrain Loss: 0.126594\n",
            "\n",
            "[EPOCH: 5], \tTest Loss: 0.0058, \tTest Accuracy: 94.12% \n",
            "\n",
            "Train Epoch: 6 [0/244 (0%)]\tTrain Loss: 0.118441\n",
            "Train Epoch: 6 [160/244 (62%)]\tTrain Loss: 0.119298\n",
            "\n",
            "[EPOCH: 6], \tTest Loss: 0.0060, \tTest Accuracy: 94.12% \n",
            "\n",
            "Train Epoch: 7 [0/244 (0%)]\tTrain Loss: 0.133994\n",
            "Train Epoch: 7 [160/244 (62%)]\tTrain Loss: 0.160338\n",
            "\n",
            "[EPOCH: 7], \tTest Loss: 0.0056, \tTest Accuracy: 94.12% \n",
            "\n",
            "Train Epoch: 8 [0/244 (0%)]\tTrain Loss: 0.060647\n",
            "Train Epoch: 8 [160/244 (62%)]\tTrain Loss: 0.079517\n",
            "\n",
            "[EPOCH: 8], \tTest Loss: 0.0055, \tTest Accuracy: 94.77% \n",
            "\n",
            "Train Epoch: 9 [0/244 (0%)]\tTrain Loss: 0.160421\n",
            "Train Epoch: 9 [160/244 (62%)]\tTrain Loss: 0.198474\n",
            "\n",
            "[EPOCH: 9], \tTest Loss: 0.0057, \tTest Accuracy: 95.42% \n",
            "\n",
            "Train Epoch: 10 [0/244 (0%)]\tTrain Loss: 0.121074\n",
            "Train Epoch: 10 [160/244 (62%)]\tTrain Loss: 0.088212\n",
            "\n",
            "[EPOCH: 10], \tTest Loss: 0.0055, \tTest Accuracy: 94.77% \n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = torch.device('cuda')\n",
        "else:\n",
        "    DEVICE = torch.device('cpu')\n",
        "\n",
        "print('Using PyTorch version:', torch.__version__, ' Device:', DEVICE)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "\n",
        "!wget --no-check-certificate https://download.pytorch.org/tutorial/hymenoptera_data.zip\n",
        "\n",
        "import zipfile\n",
        "\n",
        "zip_file = 'hymenoptera_data.zip'\n",
        "zip_ref = zipfile.ZipFile(zip_file, 'r')\n",
        "zip_ref.extractall('./data')\n",
        "zip_ref.close()\n",
        "\n",
        "!rm hymenoptera_data.zip\n",
        "\n",
        "#####################################################################################################\n",
        "## 문제 1. 다음과 같은 요구 사항을 만족하는 이미지 전처리 파이프라인을 구성하는 코드를 작성하세요. ##\n",
        "## < 요구사항 >                                                                                    ##\n",
        "## (1) 훈련 데이터 : 이미지를 무작위로 자르고 크기를 224x224로 조정 & 이미지를 좌우로 무작위 반전  ##\n",
        "##                 & 각 채널(빨강, 초록, 파랑)의 평균과 표준편차를 [0.5, 0.5, 0.5]로 정규화        ##\n",
        "## (2) 검증 데이터 : 이미지를 가운데 부분만 자르고 크기를 224x224로 설정 & 이미지의 크기는 256x256 ##\n",
        "##                 & 각 채널(빨강, 초록, 파랑)의 평균과 표준편차를 [0.5, 0.5, 0.5]로 정규화        ##\n",
        "#####################################################################################################\n",
        "\n",
        "#####################################################################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#####################################################################################################\n",
        "\n",
        "\n",
        "data_dir = 'data/hymenoptera_data'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "           data_transforms[x]) for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
        "            batch_size = BATCH_SIZE,\n",
        "            num_workers = 0,\n",
        "            shuffle = True) for x in ['train', 'val']}\n",
        "\n",
        "##############################################################################################################################################\n",
        "## 문제 2. 다음의 예시처럼 나오도록 모델 학습 및 평가 함수를 작성하세요.                                                                    ##\n",
        "## < 출력 예시 >                                                                                                                            ##\n",
        "## Train Epoch: 1 [1280/60000 (2%)]    Train Loss: 0.645321                                                                                 ##\n",
        "## Train Epoch: 1 [2560/60000 (4%)]    Train Loss: 0.612456                                                                                 ##\n",
        "## ...                                                                                                                                      ##\n",
        "## [EPOCH: 1],    Test Loss: 0.5123,    Test Accuracy: 82.45%                                                                               ##\n",
        "##                                                                                                                                          ##\n",
        "## < 힌트 >                                                                                                                                 ##\n",
        "## 1. model.train()과 model.eval()을 통해 모델의 모드를 설정할 수 있습니다.                                                                 ##\n",
        "## 2. 모델이 여러 출력을 반환하는 경우, 첫 번째 출력만 사용하여 손실을 계산하세요. [if isinstance(outputs, tuple)를 사용하세요]             ##\n",
        "## 3. 학습할 때는 옵티마이저의 기울기를 초기화하고, backward 함수를 통해 기울기를 계산한 후 옵티마이저로 가중치를 업데이트하세요.           ##\n",
        "## 4. 평가할 때는 torch.no_grad()를 사용하여 기울기를 계산하지 않도록 설정하세요.                                                           ##\n",
        "## 5. 특정 간격마다 학습 상태를 출력하세요.                                                                                                 ##\n",
        "##############################################################################################################################################\n",
        "\n",
        "##############################################################################################################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##############################################################################################################################################\n",
        "\n",
        "import torchvision.models as models\n",
        "model = models.googlenet(pretrained=False).cuda()  # GoogLeNet instead of ResNet18\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)\n",
        "model = model.cuda()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "print(model)\n",
        "\n",
        "print('미리 학습되지 않은 GoogLeNet 학습을 실행하며 Test set의 Loss와 Accuracy 확인하기 \\n')\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train(model, dataloaders[\"train\"], optimizer, log_interval=5)\n",
        "    test_loss, test_accuracy = evaluate(model, dataloaders[\"val\"])\n",
        "    print('\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n'.format(epoch, test_loss, test_accuracy))\n",
        "\n",
        "model = models.googlenet(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)\n",
        "model = model.cuda()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train(model, dataloaders[\"train\"], optimizer, log_interval=5)\n",
        "    valid_loss, valid_accuracy = evaluate(model, dataloaders[\"val\"])\n",
        "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f}% \\n\".format(epoch, valid_loss, valid_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 해답지"
      ],
      "metadata": {
        "id": "YYnBRBVLQI7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = torch.device('cuda')\n",
        "else:\n",
        "    DEVICE = torch.device('cpu')\n",
        "\n",
        "print('Using PyTorch version:', torch.__version__, ' Device:', DEVICE)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "\n",
        "!wget --no-check-certificate https://download.pytorch.org/tutorial/hymenoptera_data.zip\n",
        "\n",
        "import zipfile\n",
        "\n",
        "zip_file = 'hymenoptera_data.zip'\n",
        "zip_ref = zipfile.ZipFile(zip_file, 'r')\n",
        "zip_ref.extractall('./data')\n",
        "zip_ref.close()\n",
        "\n",
        "!rm hymenoptera_data.zip\n",
        "\n",
        "#####################################################################################################\n",
        "## 문제 1. 다음과 같은 요구 사항을 만족하는 이미지 전처리 파이프라인을 구성하는 코드를 작성하세요. ##\n",
        "## < 요구사항 >                                                                                    ##\n",
        "## (1) 훈련 데이터 : 이미지를 무작위로 자르고 크기를 224x224로 조정 & 이미지를 좌우로 무작위 반전  ##\n",
        "##                 & 각 채널(빨강, 초록, 파랑)의 평균과 표준편차를 [0.5, 0.5, 0.5]로 정규화        ##\n",
        "## (2) 검증 데이터 : 이미지를 가운데 부분만 자르고 크기를 224x224로 설정 & 이미지의 크기는 256x256 ##\n",
        "##                 & 각 채널(빨강, 초록, 파랑)의 평균과 표준편차를 [0.5, 0.5, 0.5]로 정규화        ##\n",
        "#####################################################################################################\n",
        "\n",
        "#####################################################################################################\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.Resize(256),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "    ]),\n",
        "}\n",
        "#####################################################################################################\n",
        "\n",
        "data_dir = 'data/hymenoptera_data'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "           data_transforms[x]) for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
        "            batch_size = BATCH_SIZE,\n",
        "            num_workers = 0,\n",
        "            shuffle = True) for x in ['train', 'val']}\n",
        "\n",
        "##############################################################################################################################################\n",
        "## 문제 2. 다음의 예시처럼 나오도록 모델 학습 및 평가 함수를 작성하세요.                                                                    ##\n",
        "## < 출력 예시 >                                                                                                                            ##\n",
        "## Train Epoch: 1 [1280/60000 (2%)]    Train Loss: 0.645321                                                                                 ##\n",
        "## Train Epoch: 1 [2560/60000 (4%)]    Train Loss: 0.612456                                                                                 ##\n",
        "## ...                                                                                                                                      ##\n",
        "## [EPOCH: 1],    Test Loss: 0.5123,    Test Accuracy: 82.45%                                                                               ##\n",
        "##                                                                                                                                          ##\n",
        "## < 힌트 >                                                                                                                                 ##\n",
        "## 1. model.train()과 model.eval()을 통해 모델의 모드를 설정할 수 있습니다.                                                                 ##\n",
        "## 2. 모델이 여러 출력을 반환하는 경우, 첫 번째 출력만 사용하여 손실을 계산하세요. [if isinstance(outputs, tuple)를 사용하세요]             ##\n",
        "## 3. 학습할 때는 옵티마이저의 기울기를 초기화하고, backward 함수를 통해 기울기를 계산한 후 옵티마이저로 가중치를 업데이트하세요.           ##\n",
        "## 4. 평가할 때는 torch.no_grad()를 사용하여 기울기를 계산하지 않도록 설정하세요.                                                           ##\n",
        "## 5. 특정 간격마다 학습 상태를 출력하세요.                                                                                                 ##\n",
        "##############################################################################################################################################\n",
        "\n",
        "##############################################################################################################################################\n",
        "def train(model, train_loader, optimizer, log_interval):\n",
        "    model.train()\n",
        "    for batch_idx, (image, label) in enumerate(train_loader):\n",
        "        image = image.to(DEVICE)\n",
        "        label = label.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(image)\n",
        "        if isinstance(outputs, tuple):\n",
        "            output = outputs[0]\n",
        "        else:\n",
        "            output = outputs\n",
        "\n",
        "        loss = criterion(output, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
        "                epoch, batch_idx * len(image),\n",
        "                len(train_loader.dataset), 100. * batch_idx / len(train_loader),\n",
        "                loss.item()))\n",
        "\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for image, label in test_loader:\n",
        "            image = image.to(DEVICE)\n",
        "            label = label.to(DEVICE)\n",
        "\n",
        "            outputs = model(image)\n",
        "            if isinstance(outputs, tuple):\n",
        "                output = outputs[0]\n",
        "            else:\n",
        "                output = outputs\n",
        "\n",
        "            test_loss += criterion(output, label).item()\n",
        "            prediction = output.max(1, keepdim=True)[1]\n",
        "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    return test_loss, test_accuracy\n",
        "##############################################################################################################################################\n",
        "\n",
        "import torchvision.models as models\n",
        "model = models.googlenet(pretrained=False).cuda()  # GoogLeNet instead of ResNet18\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)\n",
        "model = model.cuda()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "print(model)\n",
        "\n",
        "print('미리 학습되지 않은 GoogLeNet 학습을 실행하며 Test set의 Loss와 Accuracy 확인하기 \\n')\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train(model, dataloaders[\"train\"], optimizer, log_interval=5)\n",
        "    test_loss, test_accuracy = evaluate(model, dataloaders[\"val\"])\n",
        "    print('\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n'.format(epoch, test_loss, test_accuracy))\n",
        "\n",
        "model = models.googlenet(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)\n",
        "model = model.cuda()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train(model, dataloaders[\"train\"], optimizer, log_interval=5)\n",
        "    valid_loss, valid_accuracy = evaluate(model, dataloaders[\"val\"])\n",
        "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f}% \\n\".format(epoch, valid_loss, valid_accuracy))"
      ],
      "metadata": {
        "id": "EDhrE1OmQKtN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}